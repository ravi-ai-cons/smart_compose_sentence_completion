{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Smart_Compose_Sentence_Completion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-ai-cons/smart_compose_sentence_completion/blob/master/Smart_Compose_Sentence_Completion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRpYGxUCON8J",
        "colab_type": "code",
        "outputId": "b3f13b7e-0ba7-4365-f2cc-affaca86b650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "# Import library packages\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, CuDNNLSTM, Dropout, Bidirectional, Concatenate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j-rupu5Q2T6",
        "colab_type": "code",
        "outputId": "454b8717-5be9-4f60-8edf-9864a90a6910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Connect Colab to Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWGpIOrdRVU6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "dbbab996-ae16-467e-8ab2-2bfcd164f8df"
      },
      "source": [
        "# Enron https://data.world/brianray/enron-email-dataset \n",
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2.csv\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9,15,44,47,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJSrGV1MxkZj",
        "colab_type": "code",
        "outputId": "11ea78ce-b100-46bd-95a9-59736fe1a3aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Enron https://data.world/brianray/enron-email-dataset part wise\n",
        "# data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2_100k_chunk_1_of_6.csv\")\n",
        "# data.append(pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2_100k_chunk_2_of_6.csv\", ignore_index=True))\n",
        "# data.append(pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2_100k_chunk_3_of_6.csv\", ignore_index=True))\n",
        "# data.append(pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2_100k_chunk_4_of_6.csv\", ignore_index=True))\n",
        "# data.append(pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2_100k_chunk_5_of_6.csv\", ignore_index=True))\n",
        "# data.append(pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2_100k_chunk_6_of_6.csv\", ignore_index=True))\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9,15,38,41,44) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfsCV6ZnvfUR",
        "colab_type": "code",
        "outputId": "286ec20d-016c-4386-db42-b0d6afbf78e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "517401"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yrfbrBGRpOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Consider emails with limited words and that are Non-replies\n",
        "sample_data = data[(data['content'].str.len() < 100) & ~(data['subject'].str.contains('Re:', na=False))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "121c0674-edf5-42ee-e5df-b9df8a4dcf7e",
        "id": "NBn2uVmsuXMK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(sample_data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-9LtwQQtpIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sample_data.to_csv('/content/drive/My Drive/Colab Notebooks/enron_sample_data_100NR.csv', index=False, encoding='utf8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy5v9Pawv4-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = sample_data['content']\n",
        "# corpus = data['content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pELEri9tRM98",
        "colab_type": "code",
        "outputId": "730c515b-a5e6-4222-b465-87621925c7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(corpus)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3hRv6hUzV3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_special_chars(text, punct):\n",
        "    for p in punct:\n",
        "        text = text.replace(p, '')\n",
        "    return text\n",
        "\n",
        "def preprocess(data):\n",
        "    output = []\n",
        "    punct = '#$%&*+-/<=>[\\\\]@^_`{|}~\\t\\n'\n",
        "    for line in data:\n",
        "         pline = clean_special_chars(str(line).lower(), punct)\n",
        "         output.append(pline)\n",
        "    return output  \n",
        "\n",
        "def generate_dataset():\n",
        "    processed_corpus = preprocess(corpus)    \n",
        "    output = []\n",
        "    for line in processed_corpus:\n",
        "        for i in range(1, len(line)):\n",
        "            data = []\n",
        "            x_ngram = '<start> '+ line[:i+1] + ' <end>'\n",
        "            y_ngram = '<start> '+ line[i+1:] + ' <end>'\n",
        "            data.append(x_ngram)\n",
        "            data.append(y_ngram)\n",
        "            output.append(data)\n",
        "    print(\"Dataset prepared with prefix and suffixes for RNN as part of teacher forcing technique\")\n",
        "    # print(pd.DataFrame(output, columns=['input', 'output']).iloc[65:80])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY33xc1JLYvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ComposeIndex():\n",
        "    def __init__(self, phrase):\n",
        "        self.phrase = phrase\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for sub_phrase in self.phrase:\n",
        "            self.vocab.update(sub_phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word\n",
        "\n",
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "def load_dataset():\n",
        "    pairs = generate_dataset()\n",
        "    in_phrase = ComposeIndex(x_ngram for x_ngram, y_ngram in pairs)\n",
        "    out_phrase = ComposeIndex(y_ngram for x_ngram, y_ngram in pairs)\n",
        "    input_data = [[in_phrase.word2idx[s] for s in x_ngram.split(' ')] for x_ngram, y_ngram in pairs]\n",
        "    output_data = [[out_phrase.word2idx[s] for s in y_ngram.split(' ')] for x_ngram, y_ngram in pairs]\n",
        "\n",
        "    # print(input_data[:20])\n",
        "    # print(in_phrase.phrase)\n",
        "    # print(in_phrase.word2idx)\n",
        "    # print(in_phrase.idx2word)\n",
        "    # print(in_phrase.vocab)\n",
        "\n",
        "    max_length_in = max_length(input_data)\n",
        "    max_length_out = max_length(output_data)\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
        "    return input_data, output_data, in_phrase, out_phrase, max_length_in, max_length_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7RdTHZmUvBv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ca01f4ed-e82e-40af-cedd-17f3d9df1419"
      },
      "source": [
        "# load_dataset()\n",
        "input_data, teacher_data, input_phrase, target_phrase, len_input, len_target = load_dataset()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for RNN as part of teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmttJtpoLiCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "\n",
        "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\n",
        "# so a simple Keras validation split will be problematic if not shuffled.\n",
        "p = np.random.permutation(len(input_data))\n",
        "input_data = input_data[p]\n",
        "teacher_data = teacher_data[p]\n",
        "target_data = target_data[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQ0ax6BLnwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "BUFFER_SIZE = len(input_data)\n",
        "BATCH_SIZE = 128\n",
        "embedding_dim = 300\n",
        "units = 128\n",
        "vocab_in_size = len(input_phrase.word2idx)\n",
        "vocab_out_size = len(target_phrase.word2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MjPztpyeR1o6",
        "colab": {}
      },
      "source": [
        "# len_input\n",
        "# embedding_dim = 300\n",
        "# units = 128\n",
        "# vocab_in_size = len(input_phrase.word2idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg_H6p3kNXsZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "outputId": "cea1eeaf-e7b1-45a4-a86c-a2867b7bd5a4"
      },
      "source": [
        "# Creating the Encoder layers.\n",
        "encoder_inputs = Input(shape=(len_input,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "\n",
        "# Bidirectional LSTM\n",
        "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True, return_state=True))\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "state_h = Concatenate()([fstate_h, bstate_h])\n",
        "state_c = Concatenate()([fstate_c, bstate_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Creating the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers are added to model to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
        "\n",
        "# Training model that combines the encoder and the decoder.\n",
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_out)\n",
        "\n",
        "# Using 'sparse_categorical_crossentropy' expanding 'decoder_out' into a massive one-hot array is not required.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 27, 300)      23429100    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 27, 256), (N 440320      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    26040900    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 86803)  11197587    dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 61,712,195\n",
            "Trainable params: 61,712,195\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeuYVD9hNnuK",
        "colab_type": "code",
        "outputId": "38d0aec5-cf3e-4bc0-b175-37281184ee58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "epochs = 2\n",
        "history = model.fit([input_data, teacher_data], target_data,\n",
        "                    batch_size=BATCH_SIZE, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1472148 samples, validate on 368038 samples\n",
            "Epoch 1/2\n",
            "1472148/1472148 [==============================] - 5692s 4ms/sample - loss: 0.9206 - sparse_categorical_accuracy: 0.8587 - val_loss: 0.4567 - val_sparse_categorical_accuracy: 0.9228\n",
            "Epoch 2/2\n",
            "1472148/1472148 [==============================] - 5670s 4ms/sample - loss: 0.4524 - sparse_categorical_accuracy: 0.9192 - val_loss: 0.3380 - val_sparse_categorical_accuracy: 0.9441\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEtgUyq5n2fM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5a93cad8-1d45-4d8e-d381-167b2f01525a"
      },
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/smart_compose_model_save_200217_3.h5', overwrite=False, include_optimizer=True, save_format=None, signatures=None)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TensorFlow optimizers do not make it possible to access optimizer attributes or optimizer state after instantiation. As a result, we cannot save the optimizer as part of the model save file. You will have to compile your model again after loading it. Prefer using a Keras optimizer instead (see keras.io/optimizers).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdwg_HZzN4wV",
        "colab_type": "code",
        "outputId": "ee16492e-6a81-43b6-d7ef-61cc9ed907f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Plot the results of the training.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCJaCWogowEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZCdq_6t-oe3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "5369bf84-f24f-4108-d3ab-a48e5f572da4"
      },
      "source": [
        "# Loading model\n",
        "compose_model = tf.keras.models.load_model('/content/drive/My Drive/Colab Notebooks/smart_compose_model_save_200217_3.h5')\n",
        "compose_model.summary()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 27, 300)      23429100    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 27, 256), (N 440320      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    26040900    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 86803)  11197587    dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 61,712,195\n",
            "Trainable params: 61,712,195\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9apQjnAKrZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model.save_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200217_3.h5\")\n",
        "inf_model.save_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200217_3.h5\")\n",
        "\n",
        "encoder_model_json = encoder_model.to_json()\n",
        "inference_model_json = inf_model.to_json()\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200217_3.json\", \"w\") as json_file:\n",
        "    json.dump(json.loads(encoder_model_json), json_file, indent=4)\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200217_3.json\", \"w\") as json_file:\n",
        "    json.dump(json.loads(inference_model_json), json_file, indent=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jjg6Wb0AG5Bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "a6f146cd-d7b1-41be-fade-db968da8529d"
      },
      "source": [
        "tf.saved_model.save(encoder_model, \"/content/drive/My Drive/Colab Notebooks/tf_models/\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of object <tensorflow.python.keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7f6246cd27f0>, because an error occurred while tracing layer functions. Error message: Layer has 2 states but was passed 0 initial states.\n",
            "WARNING:tensorflow:Skipping full serialization of object <tensorflow.python.keras.layers.cudnn_recurrent.CuDNNLSTM object at 0x7f6246cd2fd0>, because an error occurred while tracing layer functions. Error message: Layer has 2 states but was passed 0 initial states.\n",
            "INFO:tensorflow:Assets written to: /content/drive/My Drive/Colab Notebooks/tf_models/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EmzVysTusLFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converts the given sentence into a vector of word_Ids\n",
        "# Output is 1-D: [timesteps/words]\n",
        "def sentence_to_vector(sentence, phrase):\n",
        "    pre = sentence\n",
        "    vec = np.zeros(len_input)\n",
        "    sentence_list = [phrase.word2idx[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(sentence_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model and a decoder/inference model,\n",
        "def translate(input_sentence, encoder_model, inference_model):\n",
        "    sv = sentence_to_vector(input_sentence, input_phrase)\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = encoder_model.predict(x=sv)\n",
        "    \n",
        "    start_vec = target_phrase.word2idx[\"<start>\"]\n",
        "    stop_vec = target_phrase.word2idx[\"<end>\"]\n",
        "    \n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"<start>\"\n",
        "    output_sentence = \"\"\n",
        "    i = 0\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\n",
        "        i += 1\n",
        "        if cur_word != \"<start>\":\n",
        "            output_sentence = output_sentence + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        [nvec, sh, sc] = inference_model.predict(x=x_in)\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = target_phrase.idx2word[np.argmax(nvec[0,0])]\n",
        "    return output_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VrbfyB_Mk76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200217_3.json\", 'r') as json_file:\n",
        "  enc_loaded_model_json = json_file.read()\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200217_3.json\", 'r') as json_file:\n",
        "  inf_loaded_model_json = json_file.read()\n",
        "\n",
        "enc_loaded_model = model_from_json(enc_loaded_model_json)\n",
        "inf_loaded_model = model_from_json(inf_loaded_model_json)\n",
        "\n",
        "enc_loaded_model.load_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200217_3.h5\")\n",
        "inf_loaded_model.load_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200217_3.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GumzcoWHHfG9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "34110d80-94d3-4d47-fb4a-646bba35866b"
      },
      "source": [
        "tf_loaded_model = tf.saved_model.load(export_dir=\"/content/drive/My Drive/Colab Notebooks/tf_models/\", tags=None)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-3daea544b504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_loaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/My Drive/Colab Notebooks/tf_models/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: load() missing 1 required positional argument: 'sess'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj5_bg4vyQJr",
        "colab_type": "code",
        "outputId": "8faaf480-873b-4097-8c39-a9915dc78f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "test = [\n",
        "    'hi there',\n",
        "    'hell',\n",
        "    'presentation please fin',\n",
        "    'please find at',\n",
        "    'please gra',\n",
        "    'have a nice we',\n",
        "    'let me ',\n",
        "    'promotion congrats ',\n",
        "    'christmas Merry ',\n",
        "    'please rev',\n",
        "    'please ca',\n",
        "    'thanks fo',\n",
        "    'Let me kno',\n",
        "    'Let me know if y',\n",
        "    'this soun',\n",
        "    'is this call going t'\n",
        "]\n",
        "  \n",
        "output = []  \n",
        "for t in test:  \n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), encoder_model, inf_model)})\n",
        "  output.append({\"Input seq\":t.lower(), \"Pred. Seq\":translate(t.lower(), enc_loaded_model, inf_loaded_model)})\n",
        "\n",
        "results_df = pd.DataFrame.from_dict(output) \n",
        "results_df.head(len(test))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Input seq</th>\n",
              "      <th>Pred. Seq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi there</td>\n",
              "      <td>have a good read.  salon.com news by any means necessary.url</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi there</td>\n",
              "      <td>have a good read.  salon.com news by any means necessary.url</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hell</td>\n",
              "      <td>re are the adjustments to be made for oct. before rolling the file. dutch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hell</td>\n",
              "      <td>re are the adjustments to be made for oct. before rolling the file. dutch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>presentation please fin</td>\n",
              "      <td>find the weekly report for week ending of june 2000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>presentation please fin</td>\n",
              "      <td>find the weekly report for week ending of june 2000.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>please find at</td>\n",
              "      <td>note you received the limit request for european weather limits. thor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>please find at</td>\n",
              "      <td>note you received the limit request for european weather limits. thor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>please gra</td>\n",
              "      <td>ll the attached outage report. jerry graves 7133458923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>please gra</td>\n",
              "      <td>ll the attached outage report. jerry graves 7133458923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>have a nice we</td>\n",
              "      <td>reminder to go to the nuggets tomorrow. they are playing chicago.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>have a nice we</td>\n",
              "      <td>reminder to go to the nuggets tomorrow. they are playing chicago.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>let me</td>\n",
              "      <td>know if you have any questions. thanks, fran chang 503.464.7973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>let me</td>\n",
              "      <td>know if you have any questions. thanks, fran chang 503.464.7973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>promotion congrats</td>\n",
              "      <td>on your promotion. i am still on the 53000 list. i hope to have it to you do.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>promotion congrats</td>\n",
              "      <td>on your promotion. i am still on the 53000 list. i hope to have it to you do.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Input seq                                                                       Pred. Seq\n",
              "0   hi there                   have a good read.  salon.com news by any means necessary.url                \n",
              "1   hi there                   have a good read.  salon.com news by any means necessary.url                \n",
              "2   hell                      re are the adjustments to be made for oct. before rolling the file. dutch    \n",
              "3   hell                      re are the adjustments to be made for oct. before rolling the file. dutch    \n",
              "4   presentation please fin    find the weekly report for week ending of june 2000.                        \n",
              "5   presentation please fin    find the weekly report for week ending of june 2000.                        \n",
              "6   please find at             note you received the limit request for european weather limits. thor       \n",
              "7   please find at             note you received the limit request for european weather limits. thor       \n",
              "8   please gra                ll the attached outage report. jerry graves 7133458923                       \n",
              "9   please gra                ll the attached outage report. jerry graves 7133458923                       \n",
              "10  have a nice we             reminder to go to the nuggets tomorrow. they are playing chicago.           \n",
              "11  have a nice we             reminder to go to the nuggets tomorrow. they are playing chicago.           \n",
              "12  let me                    know if you have any questions. thanks, fran chang 503.464.7973              \n",
              "13  let me                    know if you have any questions. thanks, fran chang 503.464.7973              \n",
              "14  promotion congrats        on your promotion. i am still on the 53000 list. i hope to have it to you do.\n",
              "15  promotion congrats        on your promotion. i am still on the 53000 list. i hope to have it to you do."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgOq9pUYyVR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "from keras.models import load_model\n",
        "\n",
        "# serialize model to JSON\n",
        "\n",
        "model_json = inf_model.to_json()\n",
        "\n",
        "import json\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_200215_3.json\", \"w\") as json_file:\n",
        "    json.dump(json.loads(model_json), json_file, indent=4)\n",
        "\n",
        "# serialize weights to HDF5\n",
        "inf_model.save_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_200215_3.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aKX7nSS3ay8",
        "colab_type": "code",
        "outputId": "270a8bc6-06ea-4516-a913-11df8ac26aa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "t = %sx read -p ''\n",
        "# translate(t[0].lower(), enc_loaded_model, inf_loaded_model)\n",
        "translate(t[0].lower(), encoder_model, inf_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  you the the the the 1, <pad>'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFv5_YBu9Bp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}