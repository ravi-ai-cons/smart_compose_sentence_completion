{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Copy of Smart_Compose_Sentence_Completion_0217.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-ai-cons/smart_compose_sentence_completion/blob/master/Copy_of_Smart_Compose_Sentence_Completion_0217.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRpYGxUCON8J",
        "colab_type": "code",
        "outputId": "b3f13b7e-0ba7-4365-f2cc-affaca86b650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        }
      },
      "source": [
        "# Import library packages\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Embedding, CuDNNLSTM, Dropout, Bidirectional, Concatenate\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5j-rupu5Q2T6",
        "colab_type": "code",
        "outputId": "454b8717-5be9-4f60-8edf-9864a90a6910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Connect Colab to Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWGpIOrdRVU6",
        "colab_type": "code",
        "outputId": "dbbab996-ae16-467e-8ab2-2bfcd164f8df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "# Enron https://data.world/brianray/enron-email-dataset \n",
        "data = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/enron_05_17_2015_with_labels_v2.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (9,15,44,47,50) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  interactivity=interactivity, compiler=compiler, result=result)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfsCV6ZnvfUR",
        "colab_type": "code",
        "outputId": "286ec20d-016c-4386-db42-b0d6afbf78e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "517401"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yrfbrBGRpOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Consider emails with limited words and that are Non-replies\n",
        "sample_data = data[(data['content'].str.len() < 100) & ~(data['subject'].str.contains('Re:', na=False))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "121c0674-edf5-42ee-e5df-b9df8a4dcf7e",
        "id": "NBn2uVmsuXMK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(sample_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy5v9Pawv4-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = sample_data['content']\n",
        "# corpus = data['content']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3hRv6hUzV3m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_special_chars(text, punct):\n",
        "    for p in punct:\n",
        "        text = text.replace(p, '')\n",
        "    return text\n",
        "\n",
        "def preprocess(data):\n",
        "    output = []\n",
        "    punct = '#$%&*+-/<=>[\\\\]@^_`{|}~\\t\\n'\n",
        "    for line in data:\n",
        "         pline = clean_special_chars(str(line).lower(), punct)\n",
        "         output.append(pline)\n",
        "    return output  \n",
        "\n",
        "def generate_dataset():\n",
        "    processed_corpus = preprocess(corpus)    \n",
        "    output = []\n",
        "    for line in processed_corpus:\n",
        "        for i in range(1, len(line)):\n",
        "            data = []\n",
        "            x_ngram = '<start> '+ line[:i+1] + ' <end>'\n",
        "            y_ngram = '<start> '+ line[i+1:] + ' <end>'\n",
        "            data.append(x_ngram)\n",
        "            data.append(y_ngram)\n",
        "            output.append(data)\n",
        "    print(\"Dataset prepared with prefix and suffixes for RNN as part of teacher forcing technique\")\n",
        "    # print(pd.DataFrame(output, columns=['input', 'output']).iloc[65:80])\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NY33xc1JLYvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ComposeIndex():\n",
        "    def __init__(self, phrase):\n",
        "        self.phrase = phrase\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for sub_phrase in self.phrase:\n",
        "            self.vocab.update(sub_phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word\n",
        "\n",
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "def load_dataset():\n",
        "    pairs = generate_dataset()\n",
        "    in_phrase = ComposeIndex(x_ngram for x_ngram, y_ngram in pairs)\n",
        "    out_phrase = ComposeIndex(y_ngram for x_ngram, y_ngram in pairs)\n",
        "    input_data = [[in_phrase.word2idx[s] for s in x_ngram.split(' ')] for x_ngram, y_ngram in pairs]\n",
        "    output_data = [[out_phrase.word2idx[s] for s in y_ngram.split(' ')] for x_ngram, y_ngram in pairs]\n",
        "\n",
        "    # print(input_data[:20])\n",
        "    # print(in_phrase.phrase)\n",
        "    # print(in_phrase.word2idx)\n",
        "    # print(in_phrase.idx2word)\n",
        "    # print(in_phrase.vocab)\n",
        "\n",
        "    max_length_in = max_length(input_data)\n",
        "    max_length_out = max_length(output_data)\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_data, maxlen=max_length_in, padding=\"post\")\n",
        "    output_data = tf.keras.preprocessing.sequence.pad_sequences(output_data, maxlen=max_length_out, padding=\"post\")\n",
        "    return input_data, output_data, in_phrase, out_phrase, max_length_in, max_length_out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7RdTHZmUvBv",
        "colab_type": "code",
        "outputId": "ca01f4ed-e82e-40af-cedd-17f3d9df1419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load_dataset()\n",
        "input_data, teacher_data, input_phrase, target_phrase, len_input, len_target = load_dataset()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset prepared with prefix and suffixes for RNN as part of teacher forcing technique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmttJtpoLiCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "\n",
        "# Shuffle all of the data in unison. This training set has the longest (e.g. most complicated) data at the end,\n",
        "# so a simple Keras validation split will be problematic if not shuffled.\n",
        "p = np.random.permutation(len(input_data))\n",
        "input_data = input_data[p]\n",
        "teacher_data = teacher_data[p]\n",
        "target_data = target_data[p]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLQ0ax6BLnwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "BUFFER_SIZE = len(input_data)\n",
        "BATCH_SIZE = 128\n",
        "embedding_dim = 300\n",
        "units = 128\n",
        "vocab_in_size = len(input_phrase.word2idx)\n",
        "vocab_out_size = len(target_phrase.word2idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg_H6p3kNXsZ",
        "colab_type": "code",
        "outputId": "cea1eeaf-e7b1-45a4-a86c-a2867b7bd5a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        }
      },
      "source": [
        "# Creating the Encoder layers.\n",
        "encoder_inputs = Input(shape=(len_input,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "\n",
        "# Bidirectional LSTM\n",
        "encoder_lstm = Bidirectional(CuDNNLSTM(units=units, return_sequences=True, return_state=True))\n",
        "encoder_out, fstate_h, fstate_c, bstate_h, bstate_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "state_h = Concatenate()([fstate_h, bstate_h])\n",
        "state_c = Concatenate()([fstate_c, bstate_c])\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Creating the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = CuDNNLSTM(units=units*2, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers are added to model to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "decoder_out = decoder_d2(Dropout(rate=.2)(decoder_d1(Dropout(rate=.2)(decoder_lstm_out))))\n",
        "\n",
        "# Training model that combines the encoder and the decoder.\n",
        "model = Model(inputs=[encoder_inputs, decoder_inputs], outputs=decoder_out)\n",
        "\n",
        "# Using 'sparse_categorical_crossentropy' expanding 'decoder_out' into a massive one-hot array is not required.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 27)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 27, 300)      23429100    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional (Bidirectional)   [(None, 27, 256), (N 440320      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 300)    26040900    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256)          0           bidirectional[0][1]              \n",
            "                                                                 bidirectional[0][3]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           bidirectional[0][2]              \n",
            "                                                                 bidirectional[0][4]              \n",
            "__________________________________________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)        [(None, None, 256),  571392      embedding_1[0][0]                \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 256)    0           cu_dnnlstm_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 128)    32896       dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, None, 128)    0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 86803)  11197587    dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 61,712,195\n",
            "Trainable params: 61,712,195\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oeuYVD9hNnuK",
        "colab_type": "code",
        "outputId": "38d0aec5-cf3e-4bc0-b175-37281184ee58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "epochs = 2\n",
        "history = model.fit([input_data, teacher_data], target_data,\n",
        "                    batch_size=BATCH_SIZE, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 1472148 samples, validate on 368038 samples\n",
            "Epoch 1/2\n",
            " 801536/1472148 [===============>..............] - ETA: 37:34 - loss: 1.1762 - sparse_categorical_accuracy: 0.8295"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEtgUyq5n2fM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('/content/drive/My Drive/Colab Notebooks/smart_compose_model_200217_3.sav', overwrite=False, include_optimizer=True, save_format=None, signatures=None)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdwg_HZzN4wV",
        "colab_type": "code",
        "outputId": "9f0b7989-2972-4f28-a70e-c34e6f9edd5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# Plot the results of the training.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['loss'], label=\"Training loss\")\n",
        "plt.plot(history.history['val_loss'], label=\"Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCJaCWogowEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_out, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units*2,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units*2,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9apQjnAKrZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_model.save_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200217_1.h5\")\n",
        "inf_model.save_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200217_3.h5\")\n",
        "\n",
        "encoder_model_json = encoder_model.to_json()\n",
        "inference_model_json = inf_model.to_json()\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200217_3.json\", \"w\") as json_file:\n",
        "    json.dump(json.loads(encoder_model_json), json_file, indent=4)\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200217_3.json\", \"w\") as json_file:\n",
        "    json.dump(json.loads(inference_model_json), json_file, indent=4)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}