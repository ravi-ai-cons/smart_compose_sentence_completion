{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of test_smart_compose.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPZXoUKVsGEhIx++0NFjcT9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ravi-ai-cons/smart_compose_sentence_completion/blob/master/Copy_of_test_smart_compose.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUYf_7FhNYYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYm43juHN7GN",
        "colab_type": "code",
        "outputId": "6287671a-d6e5-4337-dc28-f16ce6b5489d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "# Connect Colab to Google Drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbhKXWsCNc7D",
        "colab_type": "code",
        "outputId": "b75ae74d-df98-4849-d1ae-ca1a82db1d2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200216_1.json\", 'r') as json_file:\n",
        "  enc_loaded_model_json = json_file.read()\n",
        "\n",
        "with open(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200216_1.json\", 'r') as json_file:\n",
        "  inf_loaded_model_json = json_file.read()\n",
        "\n",
        "enc_loaded_model = model_from_json(enc_loaded_model_json)\n",
        "inf_loaded_model = model_from_json(inf_loaded_model_json)\n",
        "\n",
        "enc_loaded_model.load_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_enc_model_200216_1.h5\")\n",
        "inf_loaded_model.load_weights(\"/content/drive/My Drive/Colab Notebooks/smart_compose_inf_model_200216_1.h5\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drVgxyfdQe8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ComposeIndex():\n",
        "    def __init__(self, phrase):\n",
        "        self.phrase = phrase\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "        self.create_index()\n",
        "    def create_index(self):\n",
        "        for sub_phrase in self.phrase:\n",
        "            self.vocab.update(sub_phrase.split(' '))\n",
        "        self.vocab = sorted(self.vocab)\n",
        "        self.word2idx[\"<pad>\"] = 0\n",
        "        self.idx2word[0] = \"<pad>\"\n",
        "        for i,word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = i + 1\n",
        "            self.idx2word[i+1] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr-rfE2RNrKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(t):\n",
        "    return max(len(i) for i in t)\n",
        "\n",
        "# Converts the given sentence into a vector of word_Ids\n",
        "# Output is 1-D: [timesteps/words]\n",
        "def sentence_to_vector(sentence, phrase):\n",
        "    vec = np.zeros(max_length(sentence))\n",
        "    \n",
        "    for i in range(1, len(sentence)):\n",
        "        x_ngram = '<start> '+ sentence[:i+1] + ' <end>'\n",
        "    phrase = ComposeIndex(x_ngram)\n",
        "    sentence_list = [phrase.word2idx[s] for s in sentence.split(' ')]\n",
        "    for i,w in enumerate(sentence_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model and a decoder/inference model,\n",
        "def translate(input_sentence, encoder_model, inference_model):\n",
        "    sv = sentence_to_vector(input_sentence, input_sentence)\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = encoder_model.predict(x=sv)\n",
        "    \n",
        "    start_vec = target_phrase.word2idx[\"<start>\"]\n",
        "    stop_vec = target_phrase.word2idx[\"<end>\"]\n",
        "    \n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"<start>\"\n",
        "    output_sentence = \"\"\n",
        "    i = 0\n",
        "    while cur_word != \"<end>\" and i < (len_target-1):\n",
        "        i += 1\n",
        "        if cur_word != \"<start>\":\n",
        "            output_sentence = output_sentence + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        [nvec, sh, sc] = inference_model.predict(x=x_in)\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = target_phrase.idx2word[np.argmax(nvec[0,0])]\n",
        "    return output_sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H0atWNQNxn0",
        "colab_type": "code",
        "outputId": "bbf61da8-5759-43bf-ec76-9abad7cea18a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "t = %sx read -p ''\n",
        "translate(t[0].lower(), enc_loaded_model, inf_loaded_model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-e0954f7e96b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sx read -p ''\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc_loaded_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minf_loaded_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-f0eb0b42b88f>\u001b[0m in \u001b[0;36mtranslate\u001b[0;34m(input_sentence, encoder_model, inference_model)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Given an input string, an encoder model and a decoder/inference model,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minference_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0msv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0memb_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-f0eb0b42b88f>\u001b[0m in \u001b[0;36msentence_to_vector\u001b[0;34m(sentence, phrase)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<start> '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' <end>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComposeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msentence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-f0eb0b42b88f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx_ngram\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'<start> '\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' <end>'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mphrase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mComposeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_ngram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0msentence_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mphrase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mvec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'we'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxwhdtjjOnes",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}